import argparse
from pathlib import Path
import tensorflow as tf
import numpy as np
import shutil
from xmos_ai_tools import xformer as xf
import pkg_resources
import tempfile


def parse_arguments():
    parser = argparse.ArgumentParser()
    parser.add_argument("tflite_model", nargs='?',
                        help="Unoptimised TensorFlow Lite model to optimise and integrate into the VNR module")
    parser.add_argument("--copy-files", action='store_true', help="Copy generated files to vnr module")
    parser.add_argument("--module-path", type=str, default=None, help="Path to lib_vnr module to copy the new files to. Used with --copy-files")
    args = parser.parse_args()
    return args

def write_quant_spec(model, spec_path):
    interpreter_tflite = tf.lite.Interpreter(model_path=str(model))
    input_details = interpreter_tflite.get_input_details()[0]
    output_details = interpreter_tflite.get_output_details()[0]    

    assert(input_details["dtype"] in [np.int8, np.uint8]),"Error: Only 8bit input supported"
    assert(output_details["dtype"] in [np.int8, np.uint8]),"Error: Only 8bit output supported"

    # quantization spec
    input_scale, input_zero_point = input_details["quantization"]
    output_scale, output_zero_point = output_details["quantization"]

    str_index = str(Path(__file__)).find('fwk_voice')
    assert(str_index != -1)
    print(f"input_scale {input_scale}, input_zero_point {input_zero_point}, output_scale {output_scale}, output_zero_point {output_zero_point}")
    with open(spec_path, "w") as fp:
        fp.write(f"// Autogenerated from {str(Path(__file__))[str_index:]}. Do not modify\n")
        fp.write(f"// Generated using xmos-ai-tools version {ai_tools_version}\n")
        fp.write("#ifndef VNR_QUANT_SPEC_DEFINES_H\n")
        fp.write("#define VNR_QUANT_SPEC_DEFINES_H\n\n")
        fp.write(f"#define VNR_INPUT_SCALE_INV    (1.0/{input_scale})\n")
        fp.write(f"#define VNR_INPUT_ZERO_POINT   ({input_zero_point})\n")
        fp.write(f"#define VNR_OUTPUT_SCALE       ({output_scale})\n")
        fp.write(f"#define VNR_OUTPUT_ZERO_POINT   ({output_zero_point})\n")
        fp.write("\n#endif\n")

if __name__ == "__main__":
    args = parse_arguments()
    model = args.tflite_model
    model = Path(model).resolve()
    ai_tools_version = pkg_resources.get_distribution('xmos_ai_tools').version
    print(f"Running for input model {model}. Using xmos-ai-tools version {ai_tools_version}")

    # Tflite to xcore optimised tflite micro
    test_dir = Path(tempfile.mkdtemp(prefix=f"convert_{model.stem}_", dir=".")).absolute()
    output_name = str(model.stem) + "_xcore.tflite"
    xcore_opt_model = test_dir / output_name
    compiled_cpp_file = xcore_opt_model.with_suffix(".tflite.cpp")
    compiled_h_file = xcore_opt_model.with_suffix(".tflite.h")

    #xf.convert(f"{model}", f"{xcore_opt_model}", {"mlir-disable-threading": None, "xcore-reduce-memory": None})
    xf.convert(f"{model}", f"{xcore_opt_model}", {"xcore-conv-err-threshold": 0.5})
    xf.tensor_arena_size()
    xf.print_optimization_report()
    #xf.print_help()

    # Create Quant dequant spec defines file
    quiant_spec_file = test_dir / "vnr_quant_spec_defines.h"
    write_quant_spec(model, quiant_spec_file)
    
    # Optionally, copy generated files into the VNR module
    if not args.copy_files:
        print(f"XCORE optimised model, generated .cpp and .h files are saved in {test_dir}")
    else:
        files_to_add = [xcore_opt_model.name, compiled_cpp_file.name, compiled_h_file.name, quiant_spec_file.name]
        files_to_delete = []
        assert(args.module_path != None), "VNR module path --module-path needs to be specified when running with --copy-files"

        # Check if any files from vnr_module_path would need deleting   
        vnr_module_path = Path(args.module_path).resolve()
        for f in vnr_module_path.iterdir():
            if not f.name in files_to_add:
                files_to_delete.append(f.name)
          
        print(f"WARNING: Copying files to lib_vnr module {vnr_module_path}. Verify before committing!")
        # Copy quant dequant spec defines file
        shutil.copy2(quiant_spec_file, vnr_module_path)
        # Copy xcore opt model tflite file to the model's directory
        shutil.copy2(xcore_opt_model, vnr_module_path)
        # Copy the tflite_micro_compiler output .cpp file
        shutil.copy2(compiled_cpp_file, vnr_module_path)
        # Copy the tflite_micro_compiler output .h file
        shutil.copy2(compiled_h_file, vnr_module_path)
        # remove temp dir
        shutil.rmtree(test_dir)

        print(f"\nNext steps that need to be done manually:")
        if len(files_to_delete):
            print(f"\n1. From {vnr_module_path}, git rm the following files:")
            for f in files_to_delete:
                print(f"\t{f}")
        print(f"\n2. To {vnr_module_path}, git add the following files:")
        for f in files_to_add:
            print(f"\t{f}")
        print(f"\n3. Make sure that {vnr_module_path.parent}/wrapper.cpp includes model/{compiled_h_file.name} file\n")
